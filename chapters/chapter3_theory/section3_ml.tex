\newpage
\section{Σύγχρονη Μηχανική Μάθηση}
\label{sec:theory_ml}

Η μηχανική μάθηση (Machine Learning, ML) αποτελεί έναν από τους πλέον δυναμικά εξελισσόμενους τομείς της επιστήμης των υπολογιστών, με εκτεταμένες εφαρμογές στην ανάλυση δεδομένων, τη λήψη αποφάσεων και την κατανόηση της φυσικής γλώσσας. Η ουσία της μηχανικής μάθησης έγκειται στη δυνατότητα των συστημάτων να «μαθαίνουν» από τα δεδομένα και να βελτιώνουν την απόδοσή τους χωρίς ρητές οδηγίες προγραμματισμού. Με τη χρήση εξελιγμένων αλγορίθμων, τα μοντέλα μηχανικής μάθησης αναπτύσσουν ικανότητες για την εξαγωγή μοτίβων και τη δημιουργία προβλέψεων σε πραγματικό χρόνο.

Η εισαγωγή του κλάδου της μηχανικής μάθησης στην επιστήμη των υπολογιστών,
επέτρεψε στους υπολογιστές να μπορούν να αντιμετωπίσουν προβλήματα αντίληψης
για τον πραγματικό κόσμο, όσο και να παίρνουν υποκειμενικές αποφάσεις.

Οι αλγόριθμοι ML επιτρέπουν σε συστήματα Τεχνητής Νοημοσύνης (Artificial Intelligence, AI)
να προσαρμόζονται εύκολα σε καινούργια προβλήματα απαιτώντας ελάχιστη επέμβαση από τον άνθρωπο.
Για παράδειγμα, ένα νευρωνικό δίκτυο που έχει εκπαιδευτεί να αναγνωρίζει γάτες σε εικόνες,
δεν απαιτεί να σχεδιαστεί και να εκπαιδευτεί από το μηδέν για να έχει την ικανότητα
να αναγνωρίζει και σκύλους.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{./images/chapter3/AI_1.jpg}
  \caption[Κλάδοι και εφαρμογές της επιστήμης της Τεχνητής Νοημοσύνης]{Κλάδοι και εφαρμογές της επιστήμης της Τεχνητής Νοημοσύνης}
  \label{fig:ai_1}
\end{figure}

\subsection{Κατηγορίες Αλγορίθμων Μηχανικής Μάθησης}
Πολλά προβλήματα που μέχρι πριν μερικά χρόνια λύνονταν με
“χειρόγραφη”, προγραμματισμένη από τον άνθρωπο γνώση, σήμερα επιλύονται με χρήση
αλγορίθμων ML (\autoref{fig:ai_1}). Κάποια παραδείγματα αφορούν:

\begin{itemize}
  \item{Αναγνώριση ομιλίας - Speech Recognition}
  \item{Μηχανική όραση - Computer Vision}
  \begin{itemize}
    \item{Αναγνώριση αντικειμένων σε εικόνες - Object Recognition}
    \item{Αναγνώριση και εντοπισμός της θέσης αντικειμένων σε εικόνες - Object Detection}
  \end{itemize}
  \item{Αναγνώριση ηλεκτρονικών επιθέσεων στο διαδίκτυο - Cyberattack detection}
  \item{Επεξεργασία φυσικής γλώσσας - Natural Language Processing}
  \begin{itemize}
    \item{Κατανόηση της φυσικής γλώσσας του ανθρώπου - Natural Language Understanding}
    \item{Μοντελοποίηση και παραγωγή της φυσικής γλώσσας του ανθρώπου από μηχανές - Natural Language Generation}
  \end{itemize}
  \item{Μηχανές αναζήτησης - Search Engines}
  \item{Αναπαράσταση γνώσης - Knowledge Representation}
  \item{Ρομποτική}
\end{itemize}

Η επιστήμη της μηχανικής μάθησης μπορεί να ταξινομηθεί σε τρεις κύριες κατηγορίες:
\begin{enumerate}
    \item \textbf{Εποπτευόμενη Μάθηση (Supervised Learning)}: Το μοντέλο εκπαιδεύεται σε σύνολα δεδομένων όπου υπάρχουν ετικέτες (labels) που καθοδηγούν τη διαδικασία εκμάθησης.
    \item \textbf{Μη Εποπτευόμενη Μάθηση (Unsupervised Learning)}: Το μοντέλο επιχειρεί να ανακαλύψει μοτίβα και δομές από δεδομένα χωρίς προκαθορισμένες ετικέτες.
    \item \textbf{Μάθηση Ενίσχυσης (Reinforcement Learning)}: Το μοντέλο βελτιώνει τη συμπεριφορά του μέσω επαναλαμβανόμενης αλληλεπίδρασης με το περιβάλλον και αξιολόγησης των ενεργειών του. Ένα παράδειγμα εφαρμογής
    είναι η αυτόματη πλοήγηση ενός οχήματος.
\end{enumerate}

Kάποια προβλήματα είναι υβριδικά, δηλαδή συνδυασμός των πιο πάνω.
Στο \autoref{fig:ml_venn_diagram} απεικονίζεται το διάγραμμα Venn των διαφόρων 
αλγοριθμικών κατηγοριών ML.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{./images/chapter3/ml_venn_diagram.jpg}
  \caption[Διάγραμμα Venn των διαφόρων κατηγοριών μηχανικής μάθησης]{Διάγραμμα Venn των διαφόρων κατηγοριών μηχανικής μάθησης}
  \label{fig:ml_venn_diagram}
\end{figure}

Επιπλέον, οι Supervised Learning αλγόριθμοι χωρίζονται σε 2 κατηγορίες, όπως φαίνεται στο~\autoref{fig:chapter3_regressionVSclassification}, ανάλογα
με την επιθυμητή μορφή της εξόδου του αλγόριθμου ML:
\begin{itemize}
  \item{Ταξινόμησης - Classification: Πρόβλεψη μίας διακριτής κατηγορίας ή κλάσης. Η έξοδος είναι μία διακριτή ετικέτα (label).}
  \item{Παλινδρόμησης - Regression: Πρόβλεψη μίας συνεχούς μεταβλητής. Η έξοδος είναι μια συνεχής τιμή. Οι αλγόριθμοι παλινδρόμησης παράγουν ένα μοντέλο που μπορεί να προβλέψει αριθμητικές τιμές.}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/chapter3/regressionVSclassification.png}
    \caption{Διαφορά classification \& regression}
    \label{fig:chapter3_regressionVSclassification}
\end{figure}

\subsection{Προκλήσεις}
Το \textbf{overfitting} και το \textbf{underfitting} αποτελούν δύο από τις πιο σημαντικές προκλήσεις στη μηχανική μάθηση, καθώς επηρεάζουν άμεσα την ικανότητα του μοντέλου να γενικεύει σε νέα δεδομένα. Το \textbf{overfitting} προκύπτει όταν το μοντέλο μαθαίνει υπερβολικά καλά τα δεδομένα εκπαίδευσης, συμπεριλαμβανομένων τυχόν θορύβων ή σφαλμάτων, με αποτέλεσμα να αποδίδει εξαιρετικά στα δεδομένα αυτά, αλλά να αποτυγχάνει στα δεδομένα δοκιμών ή σε νέα δεδομένα. Αυτό συμβαίνει όταν το μοντέλο είναι υπερβολικά περίπλοκο, για παράδειγμα, περιέχει πολλές παραμέτρους σε σχέση με τα διαθέσιμα δεδομένα. Αντίθετα, το \textbf{underfitting} εμφανίζεται όταν το μοντέλο αποτυγχάνει να μάθει επαρκώς τα μοτίβα των δεδομένων εκπαίδευσης, με αποτέλεσμα να έχει χαμηλή απόδοση τόσο στα δεδομένα εκπαίδευσης όσο και σε νέα δεδομένα. Αυτό συμβαίνει συχνά όταν το μοντέλο είναι υπερβολικά απλό ή οι παράμετροί του δεν έχουν ρυθμιστεί σωστά. 

Η αντιμετώπιση αυτών των προκλήσεων απαιτεί προσεκτική επιλογή της αρχιτεκτονικής του μοντέλου, της μεθόδου εκπαίδευσης και των υπερπαραμέτρων, καθώς και τη χρήση τεχνικών όπως η διασταυρούμενη επικύρωση, η κανονικοποίηση και η αύξηση του μεγέθους ή της ποικιλίας των δεδομένων εκπαίδευσης. Η \textbf{διασταυρούμενη επικύρωση (cross-validation, CV)} είναι μια τεχνική που χρησιμοποιείται για την αξιολόγηση της απόδοσης ενός μοντέλου και περιλαμβάνει τη διαίρεση των δεδομένων σε υποσύνολα (folds). Το μοντέλο εκπαιδεύεται επανειλημμένα σε διαφορετικά υποσύνολα και δοκιμάζεται σε αυτά που εξαιρούνται, ώστε να εκτιμηθεί η γενική απόδοσή του σε νέα δεδομένα. Η \textbf{κανονικοποίηση (regularization)} είναι η διαδικασία μετατροπής των δεδομένων σε μία ακολουθία κανονικών μορφών, οι οποίες αποτελούνται από απλές και σαφείς σχέσεις που δεν περιέχουν επαναλήψεις. Ως στόχο έχει να περιορίσει την πολυπλοκότητα του μοντέλου, αποτρέποντας έτσι το overfitting.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/chapter3/underOverBestFitting.png}
    \caption{Πρώτο γράφημα: underfitting, Δεύτερο γράφημα: best fit, Τρίτο γράφημα: overfitting}
    \label{fig:chapter3_underOverBestFitting}
\end{figure}

\subsection{Το SVM και το One-Class SVM}
\label{subsec:svm_ocsvm}

Ένας από τους θεμελιώδεις αλγορίθμους στη μηχανική μάθηση είναι το \textit{Support Vector Machine} (SVM), το οποίο είναι ιδιαίτερα ισχυρό για την επίλυση προβλημάτων ταξινόμησης (\textit{classification}) και παλινδρόμησης (\textit{regression}). Το SVM βασίζεται στη χρήση ενός υπερεπιπέδου (\textit{hyperplane}) που διαχωρίζει δεδομένα σε διαφορετικές κλάσεις στον χώρο χαρακτηριστικών (\textit{feature space}). Ο αλγόριθμος επιλέγει το υπερεπίπεδο που μεγιστοποιεί το περιθώριο (\textit{margin}) μεταξύ των δεδομένων των διαφορετικών κλάσεων, όπως φαίνεται στο~\autoref{fig:chapter3_svmGraph}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{images/chapter3/svm-graph.png}
    \caption{Λειτουργία του SVM - Κατασκευή hyperplane με το maximum margin}
    \label{fig:chapter3_svmGraph}
\end{figure}

\subsubsection{Λειτουργία του SVM}
Το SVM λειτουργεί ως εξής:
\begin{enumerate}
    \item \textbf{Μετασχηματισμός Δεδομένων}:
    Τα δεδομένα μεταφέρονται σε έναν υψηλής διάστασης χώρο μέσω μιας μη γραμμικής συνάρτησης πυρήνα (\textit{kernel function}), όπως η RBF (Radial Basis Function) ή ο πολυωνυμικός πυρήνας. Συχνά απαιτείται μετασχηματισμός των δεδομένων σε διαφορετικό σύστημα συντεταγμένων, ώστε αυτά να είναι γραμμικά διαχωρίσιμα, όπως φαίνεται στο~\autoref{fig:chapter3_representation}.
    \item \textbf{Κατασκευή Υπερεπιπέδου}:
    Το SVM επιλέγει το υπερεπίπεδο που μεγιστοποιεί το περιθώριο μεταξύ των δύο κλάσεων δεδομένων. Στο~\autoref{fig:chapter3_optimalHyperplane} με μαύρο χρώμα φαίνεται η ευθεία που μεγιστοποιεί αυτό το περιθώριο. 
    \item \textbf{Υποστήριξη Σημείων (Support Vectors)}:
    Τα δεδομένα που βρίσκονται πλησιέστερα στο υπερεπίπεδο καλούνται \textit{support vectors} και καθορίζουν τη θέση και τον προσανατολισμό του.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{images/chapter3/optimalHyperplane.png}
    \caption{Διαχωρισμός δεδομένων με τη χρήση του αλγορίθμου SVM. Με μαύρο φαίνεται η ευθεία που μεγιστοποιεί το περιθώριο ενώ με κόκκινο και πράσινο φαίνονται άλλες - μη βέλτιστες - επιλογές ευθειών διαχωρισμού}
    \label{fig:chapter3_optimalHyperplane}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/chapter3/representation_dependency.png}
    \caption{Μη γραμμικά διαχωρίσιμα δεδομένα μετασχηματίζονται σε διαφορετικό χώρο υψηλής διάστασης}
    \label{fig:chapter3_representation}
\end{figure}

Το SVM είναι κατάλληλο για προβλήματα εποπτευόμενης μάθησης με δύο ή περισσότερες κλάσεις. Ωστόσο, όταν πρόκειται για ανίχνευση ανωμαλιών ή μοτίβων σε δεδομένα χωρίς ετικέτες, εισάγεται η επέκτασή του: το \textit{One-Class SVM}.

\subsubsection{One-Class SVM: Εξειδίκευση για Ανίχνευση Ανωμαλιών}
Το \textit{One-Class Support Vector Machine} (One-Class SVM) είναι ένας αλγόριθμος μηχανικής μάθησης που ανήκει στην κατηγορία της μη εποπτευόμενης μάθησης και χρησιμοποιείται κυρίως για την ανίχνευση ανωμαλιών και την αναγνώριση μοτίβων σε δεδομένα. Αναπτύχθηκε από τους Schölkopf et al.~\cite{scholkopf2001ocsvm}, και αποτελεί μία εκτεταμένη εφαρμογή του κλασικού SVM, που έχει σχεδιαστεί για να μοντελοποιεί τη διανομή ενός μόνο κλάδου (class). Είναι μία επέκταση του SVM που χρησιμοποιείται για προβλήματα μη εποπτευόμενης μάθησης. Σκοπός του είναι να μοντελοποιήσει την κανονική κατανομή των δεδομένων και να αναγνωρίσει αποκλίσεις ή ανωμαλίες. 

\subsubsection{Βασικές Αρχές}
Το OC-SVM προσπαθεί να περικλείσει όλα τα κανονικά δεδομένα σε έναν υψηλής διάστασης χώρο μέσω μίας υπερ-επιφάνειας (\textit{hyperplane}) ή ενός υπερσφαιρικού χώρου. Οτιδήποτε βρίσκεται εκτός αυτής της περιοχής θεωρείται ανωμαλία. Στο~\autoref{fig:chapter3_svmCircle} με μπλε χρώμα φαίνονται τα δεδομένα εκπαίδευσης που καθορίζουν τον υπερσφαιρικό χώρο. Με πράσινο φαίνονται τα δεδομένα που ανήκουν σε αυτόν τον χώρο ενώ με κόκκινο φαίνονται οι ανωμαλίες.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/chapter3/svm-circle.png}
    \caption{Επίδειξη λειτουργίας OC-SVM σε δισδιάστατο χώρο}
    \label{fig:chapter3_svmCircle}
\end{figure}

\subsubsection{Μαθηματική Διατύπωση}
Η βασική ιδέα πίσω από το One-Class SVM είναι η αναπαράσταση του συνόλου δεδομένων σε έναν υψηλής διάστασης χώρο χαρακτηριστικών μέσω μίας μη γραμμικής συνάρτησης πυρήνα (\textit{kernel function}). Στον χώρο αυτόν, το μοντέλο επιχειρεί να κατασκευάσει μία υπερ-επιφάνεια (\textit{hyperplane}) που περικλείει τη μεγαλύτερη δυνατή ποσότητα των δεδομένων, ελαχιστοποιώντας παράλληλα την απόσταση των σημείων από την επιφάνεια.

Η μαθηματική διατύπωση περιλαμβάνει την επίλυση του εξής βελτιστοποιητικού προβλήματος:
\[
\min_{\mathbf{w}, \xi, \rho} \frac{1}{2} \|\mathbf{w}\|^2 + \frac{1}{\nu N} \sum_{i=1}^N \xi_i - \rho,
\]
υπό τους περιορισμούς:
\[
(\mathbf{w} \cdot \phi(\mathbf{x}_i)) \geq \rho - \xi_i, \quad \xi_i \geq 0, \quad i = 1, \ldots, N.
\]
Όπου:
\begin{itemize}
    \item $\mathbf{w}$: Το διάνυσμα των παραμέτρων του μοντέλου.
    \item $\phi(\mathbf{x}_i)$: Η συνάρτηση που μετασχηματίζει τα δεδομένα στον χώρο χαρακτηριστικών.
    \item $\xi_i$: Οι μεταβλητές χαλάρωσης που επιτρέπουν ορισμένα σημεία να βρεθούν εκτός της επιφάνειας.
    \item $\rho$: Η παράμετρος που καθορίζει την απόσταση του υπερεπιπέδου από την αρχή.
    \item $\nu$: Ένας υπερπαράμετρος που ελέγχει το ποσοστό των σημείων που θεωρούνται εκτός της επιφάνειας.
\end{itemize}

\subsubsection{Διαδικασία Λειτουργίας}
Η διαδικασία λειτουργίας του One-Class SVM περιλαμβάνει τα εξής στάδια:
\begin{enumerate}
    \item \textbf{Εκπαίδευση}:
    Το μοντέλο εκπαιδεύεται σε ένα σύνολο δεδομένων που περιλαμβάνει μόνο τα κανονικά δεδομένα (genuine data). Ο στόχος είναι να εντοπίσει μία περιοχή στον χώρο χαρακτηριστικών που περικλείει τα δεδομένα αυτά.
    \item \textbf{Αναγνώριση}:
    Κατά τη φάση δοκιμών, τα νέα δεδομένα αξιολογούνται με βάση την απόστασή τους από την υπερ-επιφάνεια. Σημεία που βρίσκονται εκτός της καθορισμένης περιοχής θεωρούνται ανωμαλίες ή impostor δεδομένα.
    \item \textbf{Ενημέρωση}:
    Το μοντέλο μπορεί να προσαρμοστεί ώστε να ενσωματώσει νέα δεδομένα, βελτιώνοντας έτσι τη δυνατότητα ανίχνευσης μεταβαλλόμενων μοτίβων.
\end{enumerate}

\subsubsection{Πλεονεκτήματα και Εφαρμογές}
Το OC-SVM διακρίνεται για τα εξής:
\begin{itemize}
    \item \textbf{Ικανότητα Ανίχνευσης Ανωμαλιών}:
    Το OC-SVM έχει αποδειχθεί εξαιρετικά αποτελεσματικό στην ανίχνευση ανωμαλιών, καθώς μπορεί να ανιχνεύσει μοτίβα σε δεδομένα χωρίς ετικέτες, καθιστώντας το ιδανικό για ανίχνευση απάτης ή βλάβης~\cite{scholkopf2001ocsvm}.
    \item \textbf{Ευελιξία}:
    Μπορεί να εφαρμοστεί σε διάφορους τύπους δεδομένων, από κείμενο και αριθμητικά δεδομένα μέχρι εικόνες~\cite{seo2007application}.
\end{itemize}

Το One-Class SVM αποτελεί ένα θεμελιώδες εργαλείο για την ανίχνευση ανωμαλιών. Έχει εφαρμοστεί επιτυχώς σε πολλαπλά πεδία, όπως η ανίχνευση επιθέσεων σε συστήματα SCADA~\cite{laskov2004intrusion}, η ανάλυση βιομετρικών δεδομένων~\cite{hong2008fingerprint}, καθώς και σε προβλήματα ανίχνευσης και παρακολούθησης συστημάτων σε πραγματικό χρόνο~\cite{sun2017abnormal}. Η χρήση του One-Class SVM στην παρούσα εργασία επιτρέπει τη δημιουργία εξατομικευμένων μοντέλων αυθεντικοποίησης και ανίχνευσης ανωμαλιών μεταξύ των χρηστών.