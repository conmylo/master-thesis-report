\section{Εκπαίδευση μοντέλων}
\label{sec:implementation_train}

Η εκπαίδευση των μοντέλων αποτελεί έναν κρίσιμο πυλώνα του συστήματος αυθεντικοποίησης. Στη συγκεκριμένη εργασία, βασιζόμαστε στον αλγόριθμο \textit{One-Class SVM}, όπως έχει περιγραφεί στην~\autoref{subsec:svm_ocsvm}, για να εκπαιδεύσουμε τα μοντέλα που αναγνωρίζουν τα πρότυπα γραφής ενός χρήστη και απορρίπτουν τυχόν απόπειρες παραβίασης. Σε αυτή την ενότητα περιγράφεται αναλυτικά η διαδικασία εκπαίδευσης, η επιλογή των υπερπαραμέτρων και οι στρατηγικές βελτιστοποίησης.

\subsection{Προεπεξεργασία Δεδομένων Εκπαίδευσης}

Η προεπεξεργασία των δεδομένων περιλαμβάνει τα παρακάτω στάδια:
\begin{enumerate}
    \item \textbf{Ανάγνωση δεδομένων}: Το αρχείο δεδομένων περιέχει τις στήλες \texttt{author} και \texttt{content}. Τα δεδομένα διαχωρίζονται με βάση τον συγγραφέα.
    \item \textbf{Διαχωρισμός σε σύνολα}:
    \begin{itemize}
        \item Σύνολο Εκπαίδευσης: 85\% των δεδομένων.
        \item Σύνολο Δοκιμών: 15\% των δεδομένων, αποθηκεύεται για αξιολόγηση.
    \end{itemize}
    \item \textbf{Κανονικοποίηση δεδομένων}: Τα εξαγόμενα χαρακτηριστικά κανονικοποιούνται χρησιμοποιώντας τον \texttt{StandardScaler}, ώστε να έχουν μέσο όρο 0 και τυπική απόκλιση 1. Αυτή η διαδικασία είναι απαραίτητη, διότι διαφορετικά χαρακτηριστικά μπορεί να έχουν διαφορετικές κλίμακες (π.χ., ο μέσος όρος συλλαβών ανά λέξη κυμαίνεται από 0 έως 1, ενώ ο αριθμός χαρακτήρων μπορεί να είναι εκατοντάδες). Εάν τα δεδομένα δεν κανονικοποιηθούν, τα χαρακτηριστικά με μεγαλύτερες αριθμητικές τιμές ενδέχεται να έχουν μεγαλύτερη επίδραση στην εκπαίδευση και απόφαση του μοντέλου, καθιστώντας το μη αντικειμενικό. Η κανονικοποίηση εξασφαλίζει ότι όλα τα χαρακτηριστικά έχουν την ίδια αριθμητική βαρύτητα και συμβάλλει στη σωστή λειτουργία των αλγορίθμων μηχανικής μάθησης, όπως το \texttt{One-Class SVM}, οι οποίοι βασίζονται στη μέτρηση αποστάσεων.
\end{enumerate}

\subsection{Εξαγωγή και Κανονικοποίηση Χαρακτηριστικών}

Τα χαρακτηριστικά που εξάγονται από τα δεδομένα εκπαίδευσης περιγράφονται αναλυτικά στο ~\autoref{sec:implementation_features}. Μετά την εξαγωγή, εφαρμόζεται κανονικοποίηση για να διασφαλιστεί η συγκρισιμότητα μεταξύ διαφορετικών χαρακτηριστικών.

\subsection{Εκπαίδευση Μοντέλων \textit{One-Class SVM}}

Η εκπαίδευση πραγματοποιείται με τη χρήση του αλγορίθμου \textit{One-Class SVM} με πυρήνα \texttt{rbf}. Ο αλγόριθμος αυτός είναι κατάλληλος για εφαρμογές όπου υπάρχουν δεδομένα μόνο από μία κατηγορία (εν προκειμένω, του χρήστη) - one-vs-all classification. Το μοντέλο μαθαίνει τα πρότυπα της κατηγορίας αυτής και απορρίπτει ανωμαλίες.

\subsubsection{Υπερπαράμετροι του \textit{One-Class SVM}}

Οι υπερπαράμετροι του \textit{One-Class SVM} που ρυθμίστηκαν είναι:
\begin{itemize}
    \item \textbf{ν (nu)}: Ελέγχει το ποσοστό των \textit{outliers} που το μοντέλο θα ανεχθεί.
    \begin{itemize}
        \item Τιμές που δοκιμάστηκαν: $0.001$, $0.005$, $0.01$.
    \end{itemize}
    \item \textbf{gamma}: Ελέγχει την ακτίνα επιρροής ενός δείγματος.
    \begin{itemize}
        \item Τιμές που δοκιμάστηκαν: $0.05$, $0.07$, $0.1$, $0.15$, $0.2$, $0.5$.
    \end{itemize}
\end{itemize}

Για κάθε χρήστη, εκπαιδεύτηκαν 18 μοντέλα για όλους τους συνδυασμούς των παραπάνω τιμών. Τα μοντέλα αποθηκεύτηκαν στη μνήμη του συστήματος μαζί με τα μοντέλα για κανονικοποίηση νέων δεδομένων.

\subsection{Hyperparameter Tuning και Threshold Tuning}

\subsubsection{Tuning των Υπερπαραμέτρων}

Οι υπερπαράμετροι ρυθμίστηκαν μέσω πειραματισμών:
\begin{itemize}
    \item \textbf{ν (nu)}: 
    \begin{itemize}
        \item Χαμηλές τιμές αυξάνουν την ευαισθησία του μοντέλου.
        \item Υψηλές τιμές επιτρέπουν μεγαλύτερη ανοχή σε \textit{outliers}.
    \end{itemize}
    \item \textbf{gamma}:
    \begin{itemize}
        \item Χαμηλές τιμές ορίζουν ευρύτερες περιοχές απόφασης.
        \item Υψηλές τιμές επικεντρώνονται σε τοπικά μοτίβα.
    \end{itemize}
\end{itemize}

\subsubsection{Threshold Tuning}

Το threshold (\emph{κατώφλι}) είναι μια κρίσιμη παράμετρος στη διαδικασία απόφασης του μοντέλου, καθώς καθορίζει πώς θα ερμηνευτούν οι προβλέψεις για νέες εισόδους. Συγκεκριμένα, το threshold θέτει το σημείο στο οποίο το μοντέλο αποφασίζει αν μια νέα είσοδος ανήκει στην κατηγορία του γνήσιου χρήστη ή ερμηνεύεται ως απόρριψη.

\paragraph{Λειτουργία του threshold}
\begin{itemize}
    \item \textbf{Positive Decision}: Αν η απόσταση ή η πρόβλεψη ενός δείγματος είναι μεγαλύτερη από το threshold, το μοντέλο το αναγνωρίζει ως γνήσιο δείγμα.
    \item \textbf{Negative Decision}: Αν είναι μικρότερη, το μοντέλο απορρίπτει το δείγμα, θεωρώντας το ως μη γνήσιο.
\end{itemize}

\paragraph{Προσαρμογή Threshold}
Η ρύθμιση του threshold γίνεται με πειραματισμό σε διάφορες τιμές μέσα σε ένα εύρος, στη συγκεκριμένη περίπτωση μεταξύ \([-0.1, 0.8]\).

\begin{itemize}
    \item \textbf{Χαμηλό Threshold}: Εάν το threshold είναι κοντά στο \(-0.1\), το μοντέλο είναι πιο δεκτικό και αποδέχεται περισσότερα δείγματα ως γνήσια, αυξάνοντας την πιθανότητα λανθασμένων θετικών προβλέψεων.
    \item \textbf{Υψηλό Threshold}: Εάν το threshold είναι κοντά στο \(0.8\), το μοντέλο γίνεται πιο αυστηρό, απορρίπτοντας περισσότερα δείγματα ως εισβολείς.Έτσι μειώνεται η πιθανότητα λανθασμένης αποδοχής δειγμάτων ως γνήσια, αλλά αυξάνεται η πιθανότητα λανθασμένης απόρριψης γνήσιων δειγμάτων.
\end{itemize}

Η βέλτιστη ρύθμιση του threshold επιτυγχάνει έναν αποδεκτό συμβιβασμό μεταξύ ασφάλειας και χρηστικότητας, καθιστώντας το σύστημα πιο αποτελεσματικό σε πραγματικές συνθήκες.

